{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Deep Learning\n",
    "\n",
    "Profesor:\n",
    "\n",
    "Integrantes:\n",
    "- Miguel Castillo Huebner\n",
    "- Pedro Betanzo J.\n",
    "- Fernando Basterrechea\n",
    "- Ricardo Muñoz Ortega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconocimiento de señales de tránsito\n",
    "\n",
    "El reconocimiento automatizado de señales de tránsito es fundamental para mejorar la seguridad vial y habilitar tecnologías de conducción autónoma. Los sistemas avanzados de asistencia al conductor dependen de una clasificación precisa de las señales para interpretar el entorno vial en tiempo real. Este proyecto busca clasificar 58 categorías de señales de tránsito utilizando Deep Learning, con un conjunto de entrenamiento de aproximadamente 120 imágenes por clase y un conjunto de prueba con 1994 imágenes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marco Teórico\n",
    "\n",
    "Las arquitecturas de redes neuronales mas conocidas son:\n",
    "\n",
    "1. **Perceptrón Multicapa (MLP)**: Red neuronal donde cada capa esta conectada a todas las neuronas de la capa siguiente. Se utiliza para tareas básicas de clasificación y regresión. Datos estructurados y reducidos.\n",
    "\n",
    "2. **Redes Neuronales Convolucionales (CNN)**: Utilizan capas de convolución que aplican filtros sobre las entradas para extraer características espaciales, especialmente de imágenes. Se emplean en el procesamiento de imágenes, clasificación, detección de objetos, segmentación, reconocimiento facial y videos.\n",
    "\n",
    "3. **Redes Neuronales Recurrentes (RNN)**: Redes con conexiones de retroalimentación, cuentan con un estado y procesa secuencia de datos. Se utilizan en NLP, series temporales, traducción de automática, análisis de sentimiento y generación de texto.\n",
    "\n",
    "4. **Redes de Memoria a Largo Plazo (LSTM)**: Tiene la capacidad de recordar información a largo plazo, soluciona el problema del desvanecimiento del gradiente. se emplea en series temporales, predicción financiera, generación de texto, traducción, procesamiento de voz y video secuencial.\n",
    "\n",
    "5. **Unidades de Puerta Recurrente (GRU)**: Estructura mas simple y con menos parámetros de una LSTM. Se emplean en problemas de secuencias.\n",
    "\n",
    "6. **Redes Generativas Antagónicas (GAN)**: Se compone de un red generadora y otra desciminadora que compiten, la funcion de la red generadora es crear datos falsos que el discriminador debe clasificar. Se emplea en generación de imágenes, superresolución, generación de datos, deepfake y arte generativo. \n",
    "\n",
    "7. **Autoencoders**: Redes que comprimen los datos de entrada en una representación de menor dimensión para luego reconstruirlos. Se emplea en compresión de datos, reducción de dimensionalidad, eliminación de ruido, generación de datos y detección de anomalías.\n",
    "\n",
    "8. **Redes de Convolución 3D (3D-CNN)**: Capturar información espacial y temporal, su funcionamiento es similar a una CNN. Se utiliza en análisis de video, diagnóstico médico, detección de acciones y procesamiento de secuencia de imágenes.\n",
    "\n",
    "9. **Transformers**: Cuentan con mecanismos de autoatención para modelar relaciones de largo alcance en secuencias, permiten el procesamiento en paralelo de mejor forma que las RNN. Utilizadas en traducción automática, generación de texto (GPT, BERT), chatbots, análisis de sentimientos, modelación de secuencias y visión por computadoras. \n",
    "\n",
    "10. **Redes de Memoria Diferenciable (DNC)**: Utilizan memorias externas, permitiendo labores mas complejas. Empleados en navegación en grafos, recuperación de información y procesamiento de datos con estructuras complejas.\n",
    "\n",
    "11. **Redes de Capsulas (CapsNet)**: Capsulas que capturan relaciones espaciales de las características. Utilizadas en reconocimiento de imagenes, detección de objetos 3D y visión por computadora.\n",
    "\n",
    "12. **Redes de Refuerzo Profundo**: Combinación de las arquitecturas anteriores con aprendizaje por refuerzo, permitiendo al agente aprender a tomar desiciones. Empleadas en juegos, robótica, sistemas de recomendación, autónomia y simulaciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Existen 58 clases y 120 imagenes por cada una. El archivo <code>labels.csv</code> contiene la descripción de las clases de las señales de tránsito. \n",
    "\n",
    "Dispobible en: [dataset](https://www.kaggle.com/datasets/ahemateja19bec1025/traffic-sign-dataset-classification/data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Go Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Dangerous curve to the right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>Unknown6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ClassId                          Name\n",
       "24       24                      Go Right\n",
       "39       39  Dangerous curve to the right\n",
       "52       52                      Unknown6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetas = pd.read_csv('labels.csv')\n",
    "etiquetas.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traffic_Data\n",
      "    DATA\n",
      "        0\n",
      "            000_0001.png\n",
      "            000_0002.png\n",
      "            000_0003.png\n",
      "        1\n",
      "            001_0001.png\n",
      "            001_0002.png\n",
      "            001_0003.png\n"
     ]
    }
   ],
   "source": [
    "ruta = 'traffic_Data'\n",
    "i = 0\n",
    "j = 0\n",
    "for carpeta, subcarpeta, archvos in os.walk(ruta):\n",
    "    nivel = carpeta.replace(ruta, '').count(os.sep)\n",
    "    identacion = ' ' * 4 * nivel\n",
    "    print(f'{identacion}{os.path.basename(carpeta)}')\n",
    "    subidentacion = ' ' * 4 * (nivel+1)\n",
    "    for archivo in archvos:\n",
    "        print(f'{subidentacion}{archivo}')\n",
    "        if j == 2:\n",
    "            break\n",
    "        j+=1\n",
    "    j = 0\n",
    "    if i == 3:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Speed limit (5km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Speed limit (15km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Speed limit (30km/h)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClassId                  Name\n",
       "0        0   Speed limit (5km/h)\n",
       "1        1  Speed limit (15km/h)\n",
       "2        2  Speed limit (30km/h)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetas.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "- 128x128 o 224x224: Balance entre detalle y eficiencia, común para tareas de clasificación en modelos como ResNet y MobileNet.\n",
    "\n",
    "- 256x256 o 512x512: Útil para tareas que requieren más detalles (como detección de objetos compleja)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformacion = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, ),(0.5, ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.ImageFolder(root='traffic_data/DATA',transform=transformacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train =  int(0.8 * len(dataset))\n",
    "train, val = random_split(\n",
    "    dataset,\n",
    "    [\n",
    "        n_train,\n",
    "        len(dataset) - n_train\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cargador_entr = DataLoader(\n",
    "    train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ") \n",
    "cargador_val = DataLoader(\n",
    "    val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeñalesRed(nn.Module):\n",
    "\n",
    "    def __init__(self, num_clasess=58):\n",
    "        super(SeñalesRed, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3,\n",
    "            32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            32,\n",
    "            64,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            64,\n",
    "            128,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.fc1 = nn.Linear(128*8*8,512)\n",
    "        self.fc2 = nn.Linear(512, num_clasess)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_cnn = SeñalesRed(num_clasess=58) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizador y Función de Pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "floss = nn.CrossEntropyLoss() \n",
    "opt = optim.Adam(modelo_cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.239330992812202\n",
      "Accuracy: 70.14388489208633%\n",
      "Epoch 2/10, Loss: 0.618167235028176\n",
      "Accuracy: 88.48920863309353%\n",
      "Epoch 3/10, Loss: 0.23243463266463507\n",
      "Accuracy: 93.76498800959233%\n",
      "Epoch 4/10, Loss: 0.1294415474492347\n",
      "Accuracy: 96.76258992805755%\n",
      "Epoch 5/10, Loss: 0.05143349222018428\n",
      "Accuracy: 97.60191846522781%\n",
      "Epoch 6/10, Loss: 0.03274121239900567\n",
      "Accuracy: 97.84172661870504%\n",
      "Epoch 7/10, Loss: 0.029865282966472607\n",
      "Accuracy: 97.84172661870504%\n",
      "Epoch 8/10, Loss: 0.022681608736110363\n",
      "Accuracy: 98.6810551558753%\n",
      "Epoch 9/10, Loss: 0.024654920358720814\n",
      "Accuracy: 97.96163069544365%\n",
      "Epoch 10/10, Loss: 0.0069416887126863\n",
      "Accuracy: 98.8009592326139%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    modelo_cnn.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in cargador_entr:\n",
    "        opt.zero_grad()\n",
    "        outputs = modelo_cnn(images)\n",
    "        loss = floss(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(cargador_entr)}\")\n",
    "\n",
    "    # Evaluación en el conjunto de validación\n",
    "    modelo_cnn.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in cargador_val:\n",
    "            outputs = modelo_cnn(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "    torch.save(modelo_cnn.state_dict(),'SeñalesRed.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_img = 'traffic_Data/TEST/055_0021_j.png'\n",
    "imagen = Image.open(ruta_img).convert('RGB')\n",
    "imagen = transformacion(imagen)\n",
    "imagen = imagen.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase:     ClassId                     Name\n",
      "51       51  Heavy Vehicle Accidents\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    salida = modelo_cnn(imagen)\n",
    "\n",
    "_, prediccion = torch.max(salida, 1)  \n",
    "clase_pred = prediccion.item() \n",
    "print(\"Clase:\", etiquetas[etiquetas['ClassId']==clase_pred] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>No entry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ClassId      Name\n",
       "55       55  No entry"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetas[etiquetas['ClassId']==55]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
